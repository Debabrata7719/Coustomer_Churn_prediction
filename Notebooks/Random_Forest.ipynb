{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rf_title",
   "metadata": {},
   "source": [
    "# Random Forest â€” Customer Churn Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s1_md",
   "metadata": {},
   "source": [
    "## Step 1 â€” Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "s1_load",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (10000, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Satisfaction Score</th>\n",
       "      <th>Card Type</th>\n",
       "      <th>Point Earned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>DIAMOND</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>DIAMOND</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>DIAMOND</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  Complain  Satisfaction Score Card Type  \\\n",
       "0        101348.88       1         1                   2   DIAMOND   \n",
       "1        112542.58       0         1                   3   DIAMOND   \n",
       "2        113931.57       1         1                   3   DIAMOND   \n",
       "3         93826.63       0         0                   5      GOLD   \n",
       "4         79084.10       0         0                   5      GOLD   \n",
       "\n",
       "   Point Earned  \n",
       "0           464  \n",
       "1           456  \n",
       "2           377  \n",
       "3           350  \n",
       "4           425  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df = pd.read_csv('../Data/Customer-Churn-Records.csv')\n",
    "print('Shape:', df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s2_md",
   "metadata": {},
   "source": [
    "## Step 2 â€” Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "s2_clean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates removed: 0\n",
      "Remaining rows: 10000\n"
     ]
    }
   ],
   "source": [
    "# Drop identifier columns with no predictive value\n",
    "df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1, inplace=True)\n",
    "\n",
    "# Drop Complain â€” data leakage (directly causes churn, not a customer feature)\n",
    "df.drop(['Complain'], axis=1, inplace=True)\n",
    "\n",
    "# Remove duplicate rows\n",
    "before = len(df)\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(f'Duplicates removed: {before - len(df)}')\n",
    "print(f'Remaining rows: {len(df)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "s2_nulls",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null values:\n",
      " CreditScore           0\n",
      "Geography             0\n",
      "Gender                0\n",
      "Age                   0\n",
      "Tenure                0\n",
      "Balance               0\n",
      "NumOfProducts         0\n",
      "HasCrCard             0\n",
      "IsActiveMember        0\n",
      "EstimatedSalary       0\n",
      "Exited                0\n",
      "Satisfaction Score    0\n",
      "Card Type             0\n",
      "Point Earned          0\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      " CreditScore             int64\n",
      "Geography              object\n",
      "Gender                 object\n",
      "Age                     int64\n",
      "Tenure                  int64\n",
      "Balance               float64\n",
      "NumOfProducts           int64\n",
      "HasCrCard               int64\n",
      "IsActiveMember          int64\n",
      "EstimatedSalary       float64\n",
      "Exited                  int64\n",
      "Satisfaction Score      int64\n",
      "Card Type              object\n",
      "Point Earned            int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print('Null values:\\n', df.isnull().sum())\n",
    "print('\\nData types:\\n', df.dtypes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s3_md",
   "metadata": {},
   "source": [
    "## Step 3 â€” Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "s3_dist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target distribution:\n",
      "Exited\n",
      "0    7962\n",
      "1    2038\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Churn rate: 20.38%\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution (target imbalance)\n",
    "print('Target distribution:')\n",
    "print(df['Exited'].value_counts())\n",
    "print(f'\\nChurn rate: {df[\"Exited\"].mean():.2%}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "s3_outliers",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore: 15 outliers\n",
      "Age: 359 outliers\n",
      "Tenure: 0 outliers\n",
      "Balance: 0 outliers\n",
      "NumOfProducts: 60 outliers\n",
      "HasCrCard: 0 outliers\n",
      "IsActiveMember: 0 outliers\n",
      "EstimatedSalary: 0 outliers\n",
      "Satisfaction Score: 0 outliers\n",
      "Point Earned: 0 outliers\n"
     ]
    }
   ],
   "source": [
    "# Check for outliers in numeric columns using IQR\n",
    "numeric_cols = df.select_dtypes(include=['int64','float64']).drop(columns=['Exited']).columns\n",
    "for col in numeric_cols:\n",
    "    Q1, Q3 = df[col].quantile(0.25), df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers = ((df[col] < Q1 - 1.5*IQR) | (df[col] > Q3 + 1.5*IQR)).sum()\n",
    "    print(f'{col}: {outliers} outliers')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "s3_stats",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Satisfaction Score</th>\n",
       "      <th>Point Earned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>650.528800</td>\n",
       "      <td>38.921800</td>\n",
       "      <td>5.012800</td>\n",
       "      <td>76485.889288</td>\n",
       "      <td>1.530200</td>\n",
       "      <td>0.70550</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>100090.239881</td>\n",
       "      <td>0.203800</td>\n",
       "      <td>3.013800</td>\n",
       "      <td>606.515100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>96.653299</td>\n",
       "      <td>10.487806</td>\n",
       "      <td>2.892174</td>\n",
       "      <td>62397.405202</td>\n",
       "      <td>0.581654</td>\n",
       "      <td>0.45584</td>\n",
       "      <td>0.499797</td>\n",
       "      <td>57510.492818</td>\n",
       "      <td>0.402842</td>\n",
       "      <td>1.405919</td>\n",
       "      <td>225.924839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>350.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.580000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>119.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>584.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51002.110000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>410.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>652.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>97198.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100193.915000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>605.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>718.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>127644.240000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>149388.247500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>801.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>850.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250898.090000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>199992.480000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        CreditScore           Age        Tenure        Balance  NumOfProducts  \\\n",
       "count  10000.000000  10000.000000  10000.000000   10000.000000   10000.000000   \n",
       "mean     650.528800     38.921800      5.012800   76485.889288       1.530200   \n",
       "std       96.653299     10.487806      2.892174   62397.405202       0.581654   \n",
       "min      350.000000     18.000000      0.000000       0.000000       1.000000   \n",
       "25%      584.000000     32.000000      3.000000       0.000000       1.000000   \n",
       "50%      652.000000     37.000000      5.000000   97198.540000       1.000000   \n",
       "75%      718.000000     44.000000      7.000000  127644.240000       2.000000   \n",
       "max      850.000000     92.000000     10.000000  250898.090000       4.000000   \n",
       "\n",
       "         HasCrCard  IsActiveMember  EstimatedSalary        Exited  \\\n",
       "count  10000.00000    10000.000000     10000.000000  10000.000000   \n",
       "mean       0.70550        0.515100    100090.239881      0.203800   \n",
       "std        0.45584        0.499797     57510.492818      0.402842   \n",
       "min        0.00000        0.000000        11.580000      0.000000   \n",
       "25%        0.00000        0.000000     51002.110000      0.000000   \n",
       "50%        1.00000        1.000000    100193.915000      0.000000   \n",
       "75%        1.00000        1.000000    149388.247500      0.000000   \n",
       "max        1.00000        1.000000    199992.480000      1.000000   \n",
       "\n",
       "       Satisfaction Score  Point Earned  \n",
       "count        10000.000000  10000.000000  \n",
       "mean             3.013800    606.515100  \n",
       "std              1.405919    225.924839  \n",
       "min              1.000000    119.000000  \n",
       "25%              2.000000    410.000000  \n",
       "50%              3.000000    605.000000  \n",
       "75%              4.000000    801.000000  \n",
       "max              5.000000   1000.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descriptive statistics\n",
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s4_md",
   "metadata": {},
   "source": [
    "## Step 4 â€” Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "s4_split",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['CreditScore', 'Geography', 'Gender', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Satisfaction Score', 'Card Type', 'Point Earned']\n",
      "Target shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "X = df.drop('Exited', axis=1)\n",
    "y = df['Exited']\n",
    "print('Features:', X.columns.tolist())\n",
    "print('Target shape:', y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s5_md",
   "metadata": {},
   "source": [
    "## Step 5 â€” Feature Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "s5_encode",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded feature columns:\n",
      "['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary', 'Satisfaction Score', 'Point Earned', 'Geography_Germany', 'Geography_Spain', 'Gender_Male', 'Card Type_GOLD', 'Card Type_PLATINUM', 'Card Type_SILVER']\n",
      "Shape: (10000, 16)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode categorical columns: Geography, Gender, Card Type\n",
    "# drop_first=True avoids multicollinearity (dummy variable trap)\n",
    "X = pd.get_dummies(X, columns=['Geography', 'Gender', 'Card Type'], drop_first=True)\n",
    "print('Encoded feature columns:')\n",
    "print(X.columns.tolist())\n",
    "print('Shape:', X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rf_s6md",
   "metadata": {},
   "source": [
    "## Step 6 â€” Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "s6_tts",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 8000 rows | Test: 2000 rows\n",
      "Train churn rate: 20.38% | Test churn rate: 20.40%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# stratify=y ensures both splits preserve the same churn ratio\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(f'Train: {X_train.shape[0]} rows | Test: {X_test.shape[0]} rows')\n",
    "print(f'Train churn rate: {y_train.mean():.2%} | Test churn rate: {y_test.mean():.2%}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rf_s7md",
   "metadata": {},
   "source": [
    "## Step 7 â€” Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rf_import",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rf_train",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest trained\n",
      "OOB Score: 0.8311\n"
     ]
    }
   ],
   "source": [
    "# IMPROVED MODEL - Better regularization and more trees\n",
    "model = RandomForestClassifier(\n",
    "    # Number of trees\n",
    "    n_estimators=200,              # INCREASED 200 \n",
    "    \n",
    "    # Tree complexity (reduce overfitting)\n",
    "    max_depth=9,                   # REDUCED from 10\n",
    "    min_samples_split=10,          # INCREASED from 5\n",
    "    min_samples_leaf=4,            # INCREASED from 2\n",
    "    \n",
    "    # Feature sampling (improve generalization)\n",
    "    max_features='sqrt',           # NEW: use sqrt(n_features)\n",
    "    max_samples=0.8,               # NEW: bootstrap 80% samples\n",
    "    \n",
    "    # Class imbalance\n",
    "    class_weight='balanced',\n",
    "    \n",
    "    # Performance\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    \n",
    "    # Additional parameters\n",
    "    bootstrap=True,\n",
    "    oob_score=True                 # NEW: out-of-bag score\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(f'Random Forest trained')\n",
    "print(f'OOB Score: {model.oob_score_:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "val_md",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "val_compute",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, precision_score,\n",
    "    recall_score, confusion_matrix, classification_report\n",
    ")\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "train_preds = model.predict(X_train)\n",
    "test_preds  = model.predict(X_test)\n",
    "\n",
    "train_acc = accuracy_score(y_train, train_preds)\n",
    "test_acc  = accuracy_score(y_test,  test_preds)\n",
    "f1        = f1_score(y_test,        test_preds)\n",
    "precision = precision_score(y_test, test_preds)\n",
    "recall    = recall_score(y_test,    test_preds)\n",
    "\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "cv_mean   = cv_scores.mean()\n",
    "cv_std    = cv_scores.std()\n",
    "gap       = train_acc - test_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "val_acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Train / Test Accuracy ===\n",
      "Train Accuracy : 0.8752\n",
      "Test  Accuracy : 0.8320\n"
     ]
    }
   ],
   "source": [
    "# Train / Test Accuracy\n",
    "print('=== Train / Test Accuracy ===')\n",
    "print(f'Train Accuracy : {train_acc:.4f}')\n",
    "print(f'Test  Accuracy : {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "val_cv",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Cross Validation Score (5-fold) ===\n",
      "CV Mean  : 0.8344\n",
      "CV Std   : 0.0034\n",
      "CV Scores: [0.828  0.837  0.8375 0.8345 0.835 ]\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Score\n",
    "print('=== Cross Validation Score (5-fold) ===')\n",
    "print(f'CV Mean  : {cv_mean:.4f}')\n",
    "print(f'CV Std   : {cv_std:.4f}')\n",
    "print(f'CV Scores: {cv_scores.round(4)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "val_cm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Confusion Matrix ===\n",
      "[[1376  216]\n",
      " [ 120  288]]\n",
      "True  Negatives (Correctly predicted Stay)  : 1376\n",
      "False Positives (Said Churn, actually Stay) : 216\n",
      "False Negatives (Said Stay, actually Churn) : 120\n",
      "True  Positives (Correctly predicted Churn) : 288\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print('=== Confusion Matrix ===')\n",
    "cm = confusion_matrix(y_test, test_preds)\n",
    "print(cm)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f'True  Negatives (Correctly predicted Stay)  : {tn}')\n",
    "print(f'False Positives (Said Churn, actually Stay) : {fp}')\n",
    "print(f'False Negatives (Said Stay, actually Churn) : {fn}')\n",
    "print(f'True  Positives (Correctly predicted Churn) : {tp}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "val_prf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Precision / Recall / F1 ===\n",
      "Precision : 0.5714\n",
      "Recall    : 0.7059\n",
      "F1 Score  : 0.6316\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Stayed       0.92      0.86      0.89      1592\n",
      "     Churned       0.57      0.71      0.63       408\n",
      "\n",
      "    accuracy                           0.83      2000\n",
      "   macro avg       0.75      0.79      0.76      2000\n",
      "weighted avg       0.85      0.83      0.84      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Precision, Recall, F1\n",
    "print('=== Precision / Recall / F1 ===')\n",
    "print(f'Precision : {precision:.4f}')\n",
    "print(f'Recall    : {recall:.4f}')\n",
    "print(f'F1 Score  : {f1:.4f}')\n",
    "print()\n",
    "print(classification_report(y_test, test_preds, target_names=['Stayed','Churned']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "val_overfit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Overfitting Check ===\n",
      "Train Accuracy : 0.8752\n",
      "Test  Accuracy : 0.8320\n",
      "Gap            : 0.0433\n",
      "Good: No significant overfitting (gap <= 5%)\n"
     ]
    }
   ],
   "source": [
    "# Overfitting Check\n",
    "print('=== Overfitting Check ===')\n",
    "print(f'Train Accuracy : {train_acc:.4f}')\n",
    "print(f'Test  Accuracy : {test_acc:.4f}')\n",
    "print(f'Gap            : {gap:.4f}')\n",
    "if gap > 0.05:\n",
    "    print('Warning: Overfitting detected (gap > 5%)')\n",
    "else:\n",
    "    print('Good: No significant overfitting (gap <= 5%)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "val_imbalance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Class Imbalance ===\n",
      "Stayed  (0): 7962 (79.6%)\n",
      "Churned (1): 2038 (20.4%)\n",
      "Imbalance ratio: 3.91:1\n",
      "Dataset is imbalanced â€” class_weight=balanced is recommended\n"
     ]
    }
   ],
   "source": [
    "# Class Imbalance\n",
    "print('=== Class Imbalance ===')\n",
    "print(f'Stayed  (0): {(y==0).sum()} ({(y==0).mean()*100:.1f}%)')\n",
    "print(f'Churned (1): {(y==1).sum()} ({(y==1).mean()*100:.1f}%)')\n",
    "ratio = (y==0).sum() / (y==1).sum()\n",
    "print(f'Imbalance ratio: {ratio:.2f}:1')\n",
    "if ratio > 2:\n",
    "    print('Dataset is imbalanced â€” class_weight=balanced is recommended')\n",
    "else:\n",
    "    print('Dataset is relatively balanced')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "val_gen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Generalization Ability ===\n",
      "CV Mean Accuracy  : 0.8344\n",
      "Test Accuracy     : 0.8320\n",
      "CV vs Test gap    : 0.0024\n",
      "Excellent generalization â€” model performs consistently on unseen data\n"
     ]
    }
   ],
   "source": [
    "# Generalization Ability\n",
    "print('=== Generalization Ability ===')\n",
    "print(f'CV Mean Accuracy  : {cv_mean:.4f}')\n",
    "print(f'Test Accuracy     : {test_acc:.4f}')\n",
    "gen_gap = abs(cv_mean - test_acc)\n",
    "print(f'CV vs Test gap    : {gen_gap:.4f}')\n",
    "if gen_gap < 0.02:\n",
    "    print('Excellent generalization â€” model performs consistently on unseen data')\n",
    "elif gen_gap < 0.05:\n",
    "    print('Good generalization â€” minor variance between CV and test')\n",
    "else:\n",
    "    print('Poor generalization â€” model is unstable across different data splits')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "rf_feat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Features:\n",
      "          Feature  Importance\n",
      "              Age    0.338463\n",
      "    NumOfProducts    0.203929\n",
      "          Balance    0.097983\n",
      "Geography_Germany    0.053474\n",
      "   IsActiveMember    0.053049\n",
      "  EstimatedSalary    0.052766\n",
      "     Point Earned    0.051973\n",
      "      CreditScore    0.050635\n",
      "           Tenure    0.027520\n",
      "      Gender_Male    0.022523\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance\n",
    "import pandas as pd\n",
    "imp = pd.DataFrame({'Feature': X.columns, 'Importance': model.feature_importances_})\n",
    "imp = imp.sort_values('Importance', ascending=False)\n",
    "print('Top 10 Features:')\n",
    "print(imp.head(10).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "rf_mlflow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import mlflow, mlflow.sklearn\n",
    "# mlflow.set_experiment('Customer_Churn_RandomForest_Improved')\n",
    "# with mlflow.start_run():\n",
    "#     # Log all parameters\n",
    "#     mlflow.log_param('n_estimators',      200)\n",
    "#     mlflow.log_param('max_depth',         9)\n",
    "#     mlflow.log_param('min_samples_split', 10)\n",
    "#     mlflow.log_param('min_samples_leaf',  4)\n",
    "#     mlflow.log_param('max_features',      'sqrt')\n",
    "#     mlflow.log_param('max_samples',       0.8)\n",
    "#     mlflow.log_param('class_weight',      'balanced')\n",
    "    \n",
    "#     # Log metrics\n",
    "#     mlflow.log_metric('train_accuracy',   train_acc)\n",
    "#     mlflow.log_metric('test_accuracy',    test_acc)\n",
    "#     mlflow.log_metric('f1_score',         f1)\n",
    "#     mlflow.log_metric('precision',        precision)\n",
    "#     mlflow.log_metric('recall',           recall)\n",
    "#     mlflow.log_metric('cv_accuracy',      cv_mean)\n",
    "#     mlflow.log_metric('overfitting_gap',  gap)\n",
    "#     mlflow.log_metric('oob_score',        model.oob_score_)\n",
    "    \n",
    "#     mlflow.sklearn.log_model(model, name='random_forest_model_improved')\n",
    "#     print('MLflow run logged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b317f44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "âœ… MODEL PACKAGE SAVED SUCCESSFULLY!\n",
      "======================================================================\n",
      "ðŸ“¦ Model:           ../Models\\random_forest_model.pkl\n",
      "ðŸ“‹ Features:        ../Models\\feature_names.pkl\n",
      "âš™ï¸  Preprocessing:   ../Models\\preprocessing_info.pkl\n",
      "ðŸ“„ Metadata:        ../Models\\model_metadata.json\n",
      "\n",
      "ðŸŽ¯ Test Accuracy:   0.8320\n",
      "ðŸ“Š F1 Score:        0.6316\n",
      "ðŸ”¢ Total Features:  16\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Create Models directory\n",
    "models_dir = '../Models'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# 1. Save the model\n",
    "model_path = os.path.join(models_dir, 'random_forest_model.pkl')\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# 2. Save feature names (CRITICAL!)\n",
    "feature_names_path = os.path.join(models_dir, 'feature_names.pkl')\n",
    "joblib.dump(X.columns.tolist(), feature_names_path)\n",
    "\n",
    "# 3. Save preprocessing info\n",
    "preprocessing_info = {\n",
    "    'categorical_columns': ['Geography', 'Gender', 'Card Type'],\n",
    "    'numerical_columns': ['CreditScore', 'Age', 'Tenure', 'Balance', \n",
    "                         'NumOfProducts', 'HasCrCard', 'IsActiveMember', \n",
    "                         'EstimatedSalary', 'Satisfaction Score', 'Point Earned'],\n",
    "    'drop_first': True,\n",
    "    'expected_features': X.columns.tolist(),\n",
    "    'n_features': len(X.columns)\n",
    "}\n",
    "preprocessing_path = os.path.join(models_dir, 'preprocessing_info.pkl')\n",
    "joblib.dump(preprocessing_info, preprocessing_path)\n",
    "\n",
    "# 4. Save model metadata\n",
    "metadata = {\n",
    "    'model_type': 'RandomForestClassifier',\n",
    "    'test_accuracy': float(test_acc),\n",
    "    'f1_score': float(f1),\n",
    "    'precision': float(precision),\n",
    "    'recall': float(recall),\n",
    "    'n_features': len(X.columns),\n",
    "    'feature_names': X.columns.tolist()\n",
    "}\n",
    "metadata_path = os.path.join(models_dir, 'model_metadata.json')\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=4)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"âœ… MODEL PACKAGE SAVED SUCCESSFULLY!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"ðŸ“¦ Model:           {model_path}\")\n",
    "print(f\"ðŸ“‹ Features:        {feature_names_path}\")\n",
    "print(f\"âš™ï¸  Preprocessing:   {preprocessing_path}\")\n",
    "print(f\"ðŸ“„ Metadata:        {metadata_path}\")\n",
    "print(f\"\\nðŸŽ¯ Test Accuracy:   {test_acc:.4f}\")\n",
    "print(f\"ðŸ“Š F1 Score:        {f1:.4f}\")\n",
    "print(f\"ðŸ”¢ Total Features:  {len(X.columns)}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d4ac26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
